{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Notebook jupyter python for automatic extraction of information in semi-structured files using mainly regular expressions; then format them and store them in other files which will be used to populate an sql database </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import locale\n",
    "import calendar\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers Variables definition\n",
    "\n",
    "<p>Define all the variables pattern and regex we'll for future computations</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global types_marche\n",
    "types_marche = ['.*REPARTITION DES CREDITS PAR NATURE ET PAR DUREE$',\n",
    "                '.*REPARTITION DES CREDITS PAR TYPE DE CLIENTELE$',\n",
    "                '.*SERIES HISTORIQUES DES DEPOTS$',\n",
    "                '.*REPARTITION GEOGRAPHIQUE DES CREDITS PAR VILLE$',\n",
    "                '.*REPARTITION GEOGRAPHIQUE DES CREDITS PAR REGION$',\n",
    "                '.*REPARTITION DES DEPOTS PAR NATURE$',\n",
    "                '.*REPARTITION DES DEPOTS PAR TYPE DE CLIENTELE$',\n",
    "                '.*REPARTITION GEOGRAPHIQUE DES DEPOTS$',\n",
    "                '.*REPARTITION GEOGRAPHIQUE DES DEPOTS PAR VILLE$',\n",
    "                '.*REPARTITION GEOGRAPHIQUE DES DEPOTS PAR REGION$',\n",
    "                '.*REPARTITION DES CREDITS PAR DUREE ET TYPE DE CLIENTELE$',\n",
    "                '.*REPARTITION DES DEPOTS PUBLICS PAR DUREE ET TYPE DE CLIENTELE$',\n",
    "                '.*REPARTITION DES CREDITS PUBLICS PAR DUREE ET TYPE DE CLIENTELE$',\n",
    "                '.*SERIES HISTORIQUES DES CREDITS$'\n",
    "               ]\n",
    "\n",
    "comb_type = join_pattern(types_marche)\n",
    "\n",
    "\n",
    "columns = {\n",
    "    'REPARTITION DES CREDITS PAR NATURE ET PAR DUREE':['Montant', 'Banque', 'Nature', 'Type_Nature'],\n",
    "    'REPARTITION DES CREDITS PAR TYPE DE CLIENTELE':['Montant', 'Banque', 'Nature', 'Type_Nature'],\n",
    "    'SERIES HISTORIQUES DES DEPOTS':['Montant', 'Date_série', 'Banque', 'Type_Nature'],\n",
    "    'REPARTITION GEOGRAPHIQUE DES CREDITS PAR VILLE':['Nbre comptes', 'Montant', 'ville', 'Banque'],\n",
    "    'REPARTITION GEOGRAPHIQUE DES CREDITS PAR REGION':['Nbre comptes', 'Montant', 'Région', 'Banque'],\n",
    "    'REPARTITION DES DEPOTS PAR NATURE':['Montant', 'Banque', 'Nature', 'Type_Nature'],\n",
    "    'REPARTITION DES DEPOTS PAR TYPE DE CLIENTELE':['Montant', 'Banque', 'Nature', 'Type_Nature'],\n",
    "    'REPARTITION GEOGRAPHIQUE DES DEPOTS': ['Nbre comptes', 'Montant', 'ville', 'Banque'],\n",
    "    'REPARTITION GEOGRAPHIQUE DES DEPOTS PAR VILLE':['Nbre comptes', 'Montant', 'ville', 'Banque'],\n",
    "    'REPARTITION GEOGRAPHIQUE DES DEPOTS PAR REGION':['Nbre comptes', 'Montant', 'Région', 'Banque'],\n",
    "    'REPARTITION DES CREDITS PAR DUREE ET TYPE DE CLIENTELE': ['Montant', 'Banque', 'Nature', 'Type_Nature'],\n",
    "    'REPARTITION DES DEPOTS PUBLICS PAR DUREE ET TYPE DE CLIENTELE':['Montant', 'Banque', 'Nature', 'Type_Nature'],\n",
    "    'REPARTITION DES CREDITS PUBLICS PAR DUREE ET TYPE DE CLIENTELE':['Montant', 'Banque', 'Nature', 'Type_Nature'],\n",
    "    'SERIES HISTORIQUES DES CREDITS':['Montant', 'Date_série', 'Banque', 'Type_Nature']\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Patterns defintions to match all possibilities\n",
    "    and make the right action \n",
    "\"\"\"\n",
    "\n",
    "# join patterns funxtion\n",
    "def join_pattern(patterns):\n",
    "    return \"(\" + \")|(\".join(patterns) + \")\"\n",
    "\n",
    "# Nature patterns\n",
    "nature_patterns = ['CREDITS A LONG TERME', 'CREDITS A MOYEN TERME', 'CREANCES BRUTES EN SOUFFRANCE', \n",
    "                   'COMPTES DE DEPOTS A REGIME SPECIAL', 'COMPTES CREDITEURS A VUE', '.*DEPOTS VENTILABLES.*',\n",
    "                  'ADAMAOUA/NORD/EXTR. NORD', 'CENTRE/SUD/EST', 'LITTORAL', 'NORD-OUEST/SUD-OUEST', 'OUEST','ADMINISTRATION PUBLIQUE CENTRALE',\n",
    "                   'ADMINISTRATION PUBLIQUE LOCALE', 'ORGANISMES PUBLICS', 'ENTREPRISES PUBLIQUES', 'SOCIETES D\\'ASSURANCE ET CAPITAL'\n",
    "                   'ENTREPRISES INDIVIDUELLES', 'PARTICULIERS'\n",
    "                  ]\n",
    "comb_nature = join_pattern(nature_patterns)\n",
    "\n",
    "# Ignore patterns\n",
    "patterns_ignore_fields = ['.*TOTAL.*', '.*PARTS DE MARCHE.*']\n",
    "comb_ignore = join_pattern(patterns_ignore_fields)\n",
    "\n",
    "# Taked into account inside Nature\n",
    "nature_skipped_patterns = ['COMPTES DEBITEURS DE LA CLIENTELE', 'AUTRES SOMMES DUES PAR LA CLIENTELE', 'PROVISIONS CONSTITUEES']\n",
    "comb_skip = join_pattern(nature_skipped_patterns)\n",
    "\n",
    "\n",
    "# Tables to avoid\n",
    "excludes_tables = ['.*POURCENTAGE.*', 'PART DE REFINANCEMENT', 'RATIO DE TRANSFORMATION', \n",
    "                   'INTERMEDIATION', '.*SOUFFRANCE.*']\n",
    "comb_exclude = join_pattern(excludes_tables)\n",
    "\n",
    "\n",
    "# Reprocess names:\n",
    "process_names = ['.*- à vue.*', '.*- à terme.*', '.*- Crédits à court terme.*', '.*- Crédits à long terme.*', '.*- Crédits à moyen terme.*', '.*- Cptes débiteurs clientèle.*',\n",
    "                '.*- Autres sommes dues par la clientèle.*', '.*A - ADMINISTRATION PUBLIQUE CENTRALE.*', '.* B - ADMINISTRATION PUBLIQUE LOCALE.*',\n",
    "                 '.*C - ORGANISMES PUBLICS.*', '.* D - ENTREPRISES PUBLIQUES.*', '.*- à moyen et long terme.*', '.*- à court terme.*'\n",
    "                ]\n",
    "com_process_names = join_pattern(process_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions definition\n",
    "\n",
    "<p> Define the helper functions regrouping all functionnalities </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Get indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dict indices\n",
    "#global indices\n",
    "\n",
    "indices = dict()\n",
    "for typ in types_marche:\n",
    "    indices[typ] = list()\n",
    "\n",
    "# Get all tables indices\n",
    "def get_indices(datas):\n",
    "    \n",
    "    matchs_geo = ['GEOGRAPHIQUE', 'VILLE']\n",
    "    indices = []\n",
    "    \n",
    "    for i in range(len(datas)):\n",
    "        \n",
    "        value = datas[i][0]\n",
    "        if not isinstance(value, str):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        value = value.split(':')\n",
    "            \n",
    "        if len(value) != 2:\n",
    "            val = value[0]\n",
    "        else:\n",
    "            val = value[1]\n",
    "            \n",
    "        final_val = \" \".join(val.split())\n",
    "        \n",
    "        \n",
    "        if re.match(comb_type, final_val):\n",
    "            \n",
    "            typ = None\n",
    "                        \n",
    "            if matchs_geo[0] in final_val:\n",
    "                typ = 'region'\n",
    "                \n",
    "                if matchs_geo[1] in final_val:\n",
    "                    typ = 'town'\n",
    "                    \n",
    "            indices.append((i, final_val,typ, columns[final_val]))\n",
    "        else:\n",
    "            continue\n",
    "                \n",
    "                \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Get dataframe by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_type(datas, start, columns, file_date, type_banc = None):\n",
    "    \n",
    "    types = ['region', 'town']\n",
    "    \n",
    "    attribute_line = start + 2\n",
    "    \n",
    "    datas_values = {}\n",
    "\n",
    "    list_rows = []\n",
    "    end = 0\n",
    "    \n",
    "    k = start + 4\n",
    "    \n",
    "    # Check file type\n",
    "    if type_banc != None:\n",
    "        \n",
    "                \n",
    "        region_line = datas[attribute_line]\n",
    "        #region_line = region_line[~np.isnan(region_line)]\n",
    "        \n",
    "        #process region:\n",
    "        final_str=\"\"\n",
    "        for i in range(region_line.shape[0]):\n",
    "            if isinstance(region_line[i], str):\n",
    "                final_str += region_line[i]        \n",
    "        \n",
    "        split = final_str.split(':')\n",
    "        lent = len(split)\n",
    "        if type_banc == types[0]:\n",
    "            #print(final_str)\n",
    "            \n",
    "            #print((split, lent))\n",
    "            if lent == 1:\n",
    "                region = split[0]\n",
    "            else:\n",
    "                region = split[1]\n",
    "            #print(region)\n",
    "            data_add = ['Pays', region]\n",
    "        else:\n",
    "            region = split[1]\n",
    "            data_add = ['Région', region]\n",
    "            \n",
    "        attribute_line += 1\n",
    "        k +=1\n",
    "\n",
    "    \n",
    "    type_nature = None\n",
    "     \n",
    "    banks = []\n",
    "    cur_val = datas[attribute_line]\n",
    "    \n",
    "    # get all attributes \n",
    "    for j in range(datas[attribute_line].shape[0]):\n",
    "\n",
    "        if not isinstance(cur_val[j], str):\n",
    "            continue\n",
    "        elif re.match(comb_ignore,cur_val[j]) or not isinstance(cur_val[j], str):\n",
    "            break\n",
    "        banks.append(cur_val[j])\n",
    "        \n",
    "    source_end = '^Source:'\n",
    "    \n",
    "    #Compute fields\n",
    "    while end != 2:\n",
    "        \n",
    "        \n",
    "        #get Nature value\n",
    "        tab = datas[k][0]\n",
    "        # Chech first value, and try to match it        \n",
    "        if not isinstance(tab, str):\n",
    "            end +=1\n",
    "            continue\n",
    "        elif re.match(comb_nature, tab):\n",
    "            type_nature = tab\n",
    "            k += 1\n",
    "            continue\n",
    "        elif re.match(comb_skip, tab):\n",
    "            type_nature = None\n",
    "        elif re.match(comb_ignore,tab):\n",
    "            k += 1\n",
    "            continue\n",
    "            \n",
    "        if re.match(source_end, tab):\n",
    "            end = 2\n",
    "            break\n",
    "        if re.match(com_process_names, tab):\n",
    "            tab = tab.split('-')[1]\n",
    "                \n",
    "        \n",
    "        len_attr = len(banks)\n",
    "        \n",
    "        if type_banc != None:\n",
    "            length = len_attr*2\n",
    "        else:\n",
    "            length = len_attr\n",
    "            \n",
    "        \n",
    "        vals = datas[k][1:length+1]\n",
    "        \n",
    "        # Deal with region and towns\n",
    "        if type_banc != None:\n",
    "            vals = [vals[n:n+2] for n in range(0, len(vals), 2)]\n",
    "            l = [[row[0][0], row[0][1], row[1], tab]  for row in zip(vals, banks)]\n",
    "        else:\n",
    "            l = [(list(row)) + [tab, str(type_nature)]  for row in zip(vals, banks)]\n",
    "            \n",
    "        #r = [row.append(tab) for row in l]\n",
    "        list_rows += l\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "\n",
    "    # Process Nature value\n",
    "    columns = columns\n",
    "    \n",
    "    # Process dataframe\n",
    "    df = pd.DataFrame(list_rows, columns=columns)\n",
    "    df['Date_file'] = file_date\n",
    "    if type_banc != None:\n",
    "        df[data_add[0]]= data_add[1]\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Files concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_files(dict_datas):\n",
    "    \n",
    "    final_datas_dict = {}  \n",
    "    \n",
    "    print(\"Concatenation part\")\n",
    "    \n",
    "    #Process keys\n",
    "    for key in tqdm(dict_datas):\n",
    "        \n",
    "        #process new key\n",
    "        new_key = key.split()\n",
    "        new_key = \"_\".join(new_key)\n",
    "        \n",
    "        #save file process\n",
    "        new_path = \"processed_files/\" + new_key + \".xlsx\"\n",
    "        concat = pd.concat(dict_datas[key])\n",
    "        \n",
    "        #saving\n",
    "        concat.to_excel(new_path)\n",
    "        \n",
    "        #Add in the whole dictionnary\n",
    "        final_datas_dict[key] = concat\n",
    "        \n",
    "        \n",
    "    return final_datas_dict  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part\n",
    "<p> Using previous declared and implemented variables / functions </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set local language (french)\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR')\n",
    "\n",
    "directory = 'datas'\n",
    "\n",
    "all_datas = {}\n",
    "\n",
    "for subdir, dirs, files  in os.walk(directory):\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        \n",
    "        path = os.path.join(subdir, file)\n",
    "\n",
    "        #print(path)\n",
    "        \n",
    "        #read file\n",
    "        datas = pd.read_excel(path)\n",
    "        \n",
    "        path = path.split('.')\n",
    "    \n",
    "        #get corresponded date\n",
    "        month  = calendar.month_name[int(path[1])]\n",
    "        date = \" \".join([month, path[2]])\n",
    "        \n",
    "        \n",
    "        all_indices = get_indices(datas.values)\n",
    "\n",
    "        for ind in all_indices:\n",
    "\n",
    "            #compute dataframe per type\n",
    "            df = get_df_type(datas.values,ind[0], ind[3], date, ind[2])\n",
    "\n",
    "            if ind[1] not in all_datas:\n",
    "                all_datas[ind[1]] = []\n",
    "\n",
    "            all_datas[ind[1]].append(df)\n",
    "        \n",
    "concat = concatenate_files(all_datas)\n",
    "file  = list(concat.keys())[12]\n",
    "print(file)\n",
    "concat[file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Process all datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over the indices and add dataframe in corresponded key dict\n",
    "def process(datas, file_date):\n",
    "    \n",
    "    all_indices = get_indices(datas.values)\n",
    "\n",
    "    all_datas = {}\n",
    "    for ind in all_indices:\n",
    "\n",
    "        #compute dataframe per type\n",
    "        df = get_df_type(datas.values,ind[0], ind[3], file_date, ind[2])\n",
    "\n",
    "        if ind[1] not in all_datas:\n",
    "            all_datas[ind[1]] = []\n",
    "\n",
    "        all_datas[ind[1]].append(df)\n",
    "\n",
    "    return all_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Montant</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Banque</th>\n",
       "      <th>Type Nature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Montant, Nature, Banque, Type Nature]\n",
       "Index: []"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Patterns definition\n",
    "patterns = ['.*TOTAL.*', 'CREDITS A LONG TERME', 'CREDITS A MOYEN TERME', 'CREANCES BRUTES EN SOUFFRANCE']\n",
    "computed_fiels = ['.*TOTAL.*', 'PARTS DE MARCHE', '.*DEC.*']\n",
    "\n",
    "combs = \"(\" + \")|(\".join(patterns[1:]) + \")\"\n",
    "\n",
    "normal_nature = ['COMPTES DEBITEURS DE LA CLIENTELE', 'AUTRES SOMMES DUES PAR LA CLIENTELE', 'PROVISIONS CONSTITUEES']\n",
    "combs_nature = \"(\" + \")|(\".join(normal_nature) + \")\"\n",
    "\n",
    "\n",
    "# Function definition for types\n",
    "# REPARTITION DES CREDITS PAR NATURE ET PAR DUREE and REPARTITION DES CREDITS PAR TYPE DE CLIENTELE\n",
    "def get_type_1(datas, start):\n",
    "    \n",
    "     \n",
    "    attribute_line = start + 4\n",
    "    type_nature = None\n",
    "     \n",
    "    banks = []\n",
    "    cur_val = datas[attribute_line]\n",
    "    \n",
    "    # get all attributes \n",
    "    for j in range(datas[attribute_line].shape[0]):\n",
    "\n",
    "        if not isinstance(cur_val[j], str):\n",
    "            continue\n",
    "        elif re.match(patterns[0],cur_val[j]):\n",
    "            break\n",
    "        banks.append(cur_val[j])\n",
    "        \n",
    "    datas_values = {}\n",
    "\n",
    "    list_rows = []\n",
    "    end = 0\n",
    "    j = start + 4\n",
    "    \n",
    "    #Compute fiels\n",
    "    while end != 2:\n",
    "        \n",
    "        #get Nature value\n",
    "        tab = datas[j][0]\n",
    "        \n",
    "        \n",
    "        # Chech first value, and try to match it        \n",
    "        if not isinstance(tab, str):\n",
    "            end +=1\n",
    "            continue\n",
    "        elif re.match(combs, tab):\n",
    "            type_nature = tab\n",
    "            j += 1\n",
    "            continue\n",
    "        elif re.match(combs_nature, tab):\n",
    "            type_nature = None\n",
    "        elif re.match(patterns[0],tab):\n",
    "            j += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        vals = datas[j][1: len(banks)+1]\n",
    "        \n",
    "        l = [(list(row)) + [tab, str(type_nature)]  for row in zip(vals, banks)]\n",
    "        #r = [row.append(tab) for row in l]\n",
    "        list_rows += l\n",
    "        \n",
    "        j += 1\n",
    "        \n",
    "\n",
    "    # Process Nature value\n",
    "    columns = ['Montant', 'Nature', 'Banque', 'Type Nature']\n",
    "    \n",
    "    # Process dataframe\n",
    "    df = pd.DataFrame(list_rows, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function definition for type SERIES HISTORIQUES DES CREDITS\n",
    "get_type_1(datas.values, 85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
